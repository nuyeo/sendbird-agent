import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import create_tool_calling_agent, AgentExecutor
# from langchain import hub  <-- ì´ê±° ëŒ€ì‹  ì§ì ‘ ë§Œë“­ë‹ˆë‹¤
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from dotenv import load_dotenv

# ë„êµ¬ë“¤ ê°€ì ¸ì˜¤ê¸°
from app.tools import search_order_status, refund_calculator

load_dotenv()

agent_executor = None


def initialize_rag():
    global agent_executor

    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    db_path = os.path.join(BASE_DIR, "data", "chroma_db")
    file_path = os.path.join(BASE_DIR, "data", "faq.txt")

    # 1. ë²¡í„° DB ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
    embeddings = OpenAIEmbeddings()
    if os.path.exists(db_path) and os.listdir(db_path):
        print("ğŸ’¾ [AI Init] ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        db = Chroma(persist_directory=db_path, embedding_function=embeddings)
    else:
        print("ğŸ¤– [AI Init] ë¬¸ì„œë¥¼ ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤...")
        if not os.path.exists(file_path):
            print("ğŸš¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        loader = TextLoader(file_path, encoding="utf-8")
        documents = loader.load()
        text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)
        texts = text_splitter.split_documents(documents)
        db = Chroma.from_documents(texts, embeddings, persist_directory=db_path)

    # 2. Retriever ë„êµ¬ ìƒì„± (ì„¤ëª… êµ¬ì²´í™”)
    retriever = db.as_retriever()
    retriever_tool = create_retriever_tool(
        retriever,
        "search_faq",
        "Use this tool to find official policies about refund, shipping, and general guidelines."
    )

    # 3. ë„êµ¬ ëª¨ìŒ
    tools = [retriever_tool, search_order_status, refund_calculator]

    # 4. LLM ì„¤ì •
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

    # ğŸ“Œ [í•µì‹¬] í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (Hallucination ì œì–´ & ì¶œì²˜ í‘œê¸°)
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— 'í˜ë¥´ì†Œë‚˜'ì™€ 'ì œì•½ì¡°ê±´'ì„ ê°•ë ¥í•˜ê²Œ ê²ë‹ˆë‹¤.
    system_prompt = """
    You are a helpful and precise Customer Support Agent for 'Sendbird Store'.

    Your Role:
    1. Answer user questions based ONLY on the information provided by the tools (FAQ, Order Search, Refund Calculator).
    2. Do NOT use your own outside knowledge. If the user asks about general topics (e.g., "Who is Napoleon?", "Weather in Seoul"), politely refuse and say you can only help with store-related inquiries.

    Strict Guidelines:
    - If the information is NOT found in the tools, explicitly say: "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ì œê°€ ì•Œ ìˆ˜ ì—†ëŠ” ì •ë³´ì…ë‹ˆë‹¤. ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
    - Do NOT make up facts (Hallucination).
    - When using the 'search_faq' tool, always mention the source section if possible (e.g., "ê·œì • 2ì¡°ì— ë”°ë¥´ë©´...").

    Tone:
    - Be polite, professional, and concise.
    - Use Korean.
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),  # ë„êµ¬ ì‚¬ìš© ë‚´ì—­ì´ ë“¤ì–´ê°€ëŠ” ìë¦¬
    ])

    # 5. Agent ìƒì„±
    agent = create_tool_calling_agent(llm, tools, prompt)

    # 6. ì‹¤í–‰ê¸° ìƒì„±
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    print("âœ… [AI Init] Agentê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. (Custom Prompt Applied)")


def get_ai_response(user_query: str) -> str:
    if agent_executor is None:
        return "AIê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    try:
        response = agent_executor.invoke({"input": user_query})
        return response["output"]
    except Exception as e:
        print(f"ğŸš¨ Error: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."