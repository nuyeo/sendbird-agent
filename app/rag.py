import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from dotenv import load_dotenv

# ë„êµ¬ë“¤ ê°€ì ¸ì˜¤ê¸°
from app.tools import search_order_status, refund_calculator, cancel_order, transfer_to_human

load_dotenv()

agent_executor = None


def initialize_rag():
    global agent_executor

    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    db_path = os.path.join(BASE_DIR, "data", "chroma_db")
    file_path = os.path.join(BASE_DIR, "data", "faq.txt")

    # 1. ë²¡í„° DB ë¡œë“œ
    embeddings = OpenAIEmbeddings()
    if os.path.exists(db_path) and os.listdir(db_path):
        print("ğŸ’¾ [AI Init] ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        db = Chroma(persist_directory=db_path, embedding_function=embeddings)
    else:
        print("ğŸ¤– [AI Init] ë¬¸ì„œë¥¼ ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤...")
        if not os.path.exists(file_path):
            print("ğŸš¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        loader = TextLoader(file_path, encoding="utf-8")
        documents = loader.load()
        text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)
        texts = text_splitter.split_documents(documents)
        db = Chroma.from_documents(texts, embeddings, persist_directory=db_path)

    # 2. Retriever ë„êµ¬ ìƒì„±
    retriever = db.as_retriever()
    retriever_tool = create_retriever_tool(
        retriever,
        "search_faq",
        "Use this tool to find official policies about refund, shipping, and general guidelines."
    )

    # 3. ë„êµ¬ ëª¨ìŒ
    tools = [retriever_tool, search_order_status, refund_calculator, cancel_order, transfer_to_human]

    # 4. LLM ì„¤ì •
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

    # ğŸ“Œ [ìˆ˜ì • ì™„ë£Œ] ì¤‘ê´„í˜¸({})ë¥¼ ëª¨ë‘ ì œê±°í•œ ì•ˆì „í•œ í”„ë¡¬í”„íŠ¸
    system_prompt = """
    You are a helpful and precise Customer Support Agent for 'Sendbird Store'.

    Your Role:
    1. Answer user questions based ONLY on the information provided by the tools.
    2. Do NOT use your own outside knowledge.

    Decision Protocol (IMPORTANT):
    1. General Policy Questions: ALWAYS use 'search_faq' first.
    2. Specific Order Requests:
       - IF the Order ID is missing, ask the user for it.
       - YOU MUST FIRST use 'search_order_status' to get details.

    Tone and Logic Guidelines (CRITICAL):
    - Avoid unnecessary apologies. Do NOT say "Sorry" or "ì£„ì†¡í•©ë‹ˆë‹¤" if the user's request is possible.
    - Logic Check for Cancellation:
      - IF status is 'ìƒí’ˆ ì¤€ë¹„ ì¤‘' (Preparing) AND user asks "Can I cancel?":
        - SAY: "ë„¤, í˜„ì¬ 'ìƒí’ˆ ì¤€ë¹„ ì¤‘' ìƒíƒœì´ë¯€ë¡œ ì·¨ì†Œê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì·¨ì†Œí•´ ë“œë¦´ê¹Œìš”?"
      - IF status is 'ë°°ì†¡ ì¤‘' (Shipping) or 'ë°°ì†¡ ì™„ë£Œ' (Delivered):
        - SAY: "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë°°ì†¡ ìƒíƒœì—ì„œëŠ” ì·¨ì†Œê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤." 

    Strict Response Guidelines:
    - NEVER mention technical terms.
    - Speak naturally like a human agent.
    - Use Korean.
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])

    agent = create_tool_calling_agent(llm, tools, prompt)
    agent_executor_base = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # 5. ë©”ëª¨ë¦¬ ê¸°ëŠ¥ (Session IDë³„ë¡œ ëŒ€í™” ê¸°ì–µ)
    chat_history_store = {}

    def get_session_history(session_id: str):
        if session_id not in chat_history_store:
            chat_history_store[session_id] = InMemoryChatMessageHistory()
        return chat_history_store[session_id]

    agent_executor = RunnableWithMessageHistory(
        agent_executor_base,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
    )

    print("âœ… [AI Init] Agent Ready (with Memory & Handoff)")


def get_ai_response(user_query: str, user_id: str = "default") -> str:
    if agent_executor is None:
        return "AIê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    try:
        response = agent_executor.invoke(
            {"input": user_query},
            config={"configurable": {"session_id": user_id}}
        )
        return response["output"]
    except Exception as e:
        print(f"ğŸš¨ Error: {e}")
        # ì—ëŸ¬ê°€ ë‚˜ë©´ ê°„ë‹¨í•œ ë©”ì‹œì§€ ë¦¬í„´ (ì„œë²„ ì•ˆ ì£½ê²Œ)
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."